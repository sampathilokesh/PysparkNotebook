{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b3af85-3aa0-4e60-b6ed-e6b39ff7a00b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # ROW class in pyspark\n",
    "# # Row is a class ussed to create entire row as a object\n",
    "# by using those objects we can represent dataframe, these are like exension of tuple(as we use tuple in list to represent data)\n",
    "from pyspark.sql import Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "976f52aa-94ad-4319-9ed1-03b556cfb0de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  1|lokesh|   99|\n|  2|  gopi|   90|\n+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# creating row objects of a entire data by using properties(columns) \n",
    "row1=Row(id=1,name='lokesh',marks=99)\n",
    "row2=Row(id=2,name='gopi',marks=90)\n",
    "data=[row1,row2]\n",
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a712f6a-e7cc-478f-8bcd-b7529bc7144e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lokesh  and marks are :99\n"
     ]
    }
   ],
   "source": [
    "#accessing data by using row\n",
    "print(row1.name+'  and marks are :'+str(row1.marks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ab6d3a5-2c49-4c3b-afd5-2b10b7ecfb87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n|name|age|\n+----+---+\n|loki| 22|\n|gopi| 25|\n+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "#crwate class by using row\n",
    "Person=Row('name','age')\n",
    "p1=Person('loki',22)\n",
    "p2=Person('gopi',25)\n",
    "df1=spark.createDataFrame([p1,p2])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e9fe4e-f880-4305-bfb3-1312cea8763b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: string (nullable = true)\n |-- marks: struct (nullable = true)\n |    |-- maths: long (nullable = true)\n |    |-- telugu: long (nullable = true)\n\n+----+--------+\n|name|   marks|\n+----+--------+\n|loki|{25, 24}|\n|gopi|{22, 19}|\n+----+--------+\n\n"
     ]
    }
   ],
   "source": [
    "#create struct type or nested struct type\n",
    "data=[Row(name='loki',marks=Row(maths=25,telugu=24)),\\\n",
    "    Row(name='gopi',marks=Row(maths=22,telugu=19))]\n",
    "df2=spark.createDataFrame(data)\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0eaf495-eb1b-40c9-9df5-e7334ba9efe0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# column class is used to represent singlr column \n",
    "# by using column object we can do many operations  like filtering, boolean , manipulation, retrieving.\n",
    "# we create new column and it's object simply by using lit() function\n",
    "from pyspark.sql.functions import col,lit\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae1a2880-de2a-47db-91a3-d57b72967d60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  1|lokesh|   99|\n|  2|  gopi|   90|\n+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "row1=Row(id=1,name='lokesh',marks=99)\n",
    "row2=Row(id=2,name='gopi',marks=90)\n",
    "data=[row1,row2]\n",
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6dba297-1f18-4038-8576-5a53a85ad3a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+----------+\n| id|  name|marks|percentage|\n+---+------+-----+----------+\n|  1|lokesh|   99|        98|\n|  2|  gopi|   90|        98|\n+---+------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "#create new column and its static or default value using lit() function\n",
    "df.withColumn('percentage',lit('98')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78936e15-82af-4c8a-b77e-6d2813e377ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|  name|\n+------+\n|lokesh|\n|  gopi|\n+------+\n\n+------+\n|  name|\n+------+\n|lokesh|\n|  gopi|\n+------+\n\n+------+\n|  name|\n+------+\n|lokesh|\n|  gopi|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "#different ways to access columns\n",
    "df.select(df.name).show()\n",
    "df.select(df['name']).show()\n",
    "df.select(col('name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a70ce462-045c-484e-ae94-9aeb2fe7df54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>marks</th></tr></thead><tbody><tr><td>1</td><td>lokesh</td><td>99</td></tr><tr><td>2</td><td>gopi</td><td>90</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "lokesh",
         99
        ],
        [
         2,
         "gopi",
         90
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "marks",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b7d1b68-c699-47d5-9c7c-e3b2abba0d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# when and otherwise functions \n",
    "#these are used to excute the code based on condition like cases in sql\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5ac3388-07a7-4f0c-9156-673e3b523f20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>marks</th><th>result</th></tr></thead><tbody><tr><td>lokesh</td><td>99</td><td>pass</td></tr><tr><td>gopi</td><td>90</td><td>fail</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lokesh",
         99,
         "pass"
        ],
        [
         "gopi",
         90,
         "fail"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "marks",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "result",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df1=df.withColumn('result',when(col('marks')>90,'pass').ottherwise('fail'))\n",
    "df1=df.select(df.name,df.marks,when(col('marks')>90,'pass').otherwise('fail').alias('result'))\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d9b96c0-8d92-4a55-81ca-35879a129b82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# more column functions\n",
    "    # alias()\n",
    "    # cast()\n",
    "    # like()\n",
    "    # sort ->asc,desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8448de91-9ff6-4c37-b433-79fa3bf06dc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n|StudentName|StudentMarks|\n+-----------+------------+\n|     lokesh|          99|\n|       gopi|          90|\n+-----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#alias -> used to name the an existing column or alternative name of a column to existing column\n",
    "df.select(df.name.alias('StudentName'),df.marks.alias('StudentMarks')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4c43c5e-eefa-4d1d-aa92-d97e19fb0c16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- marks: long (nullable = true)\n\nroot\n |-- name: string (nullable = true)\n |-- marks: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "#cast -> used to convert one data type of column into another datatype\n",
    "df.printSchema()\n",
    "df1=df.select(df.name,df.marks.cast('int'))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b27e604-f2cb-4408-a85c-0bbc49751409",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  1|lokesh|   99|\n+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# like -> it is a wildcard function used to extract data which follows similar pattern it is used to filter data\n",
    "df.filter(df.name.like('l%')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ad2529-1063-463f-82f6-bf6c031db61e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  2|  gopi|   90|\n|  1|lokesh|   99|\n+---+------+-----+\n\n+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  1|lokesh|   99|\n|  2|  gopi|   90|\n+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# sort -> used to sort data based on particular column\n",
    "df.sort(df.marks.asc()).show()\n",
    "df.sort(df.marks.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d1457fb-f9bd-40e9-8541-07ec04cb3c6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-394609090706062>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Row\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m where\n",
       "\n",
       "\u001B[0;31mImportError\u001B[0m: cannot import name 'where' from 'pyspark.sql.functions' (/databricks/spark/python/pyspark/sql/functions.py)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)\nFile \u001B[0;32m<command-394609090706062>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Row\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m where\n\n\u001B[0;31mImportError\u001B[0m: cannot import name 'where' from 'pyspark.sql.functions' (/databricks/spark/python/pyspark/sql/functions.py)",
       "errorSummary": "<span class='ansi-red-fg'>ImportError</span>: cannot import name 'where' from 'pyspark.sql.functions' (/databricks/spark/python/pyspark/sql/functions.py)",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973cd36e-c3ad-47fd-83dd-5b48f4b12ef5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  1|lokesh|   99|\n|  2|  gopi|   90|\n|  3|   sri|   85|\n+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "row1=Row(id=1,name='lokesh',marks=99)\n",
    "row2=Row(id=2,name='gopi',marks=90)\n",
    "row3=Row(id=3,name='sri',marks=85)\n",
    "data=[row1,row2,row3]\n",
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "271e2cf3-c6c6-49d1-b741-41e700c1dad5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n| id|  name|marks|\n+---+------+-----+\n|  1|lokesh|   99|\n|  3|   sri|   85|\n+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# where and filter functions\n",
    "df.filter(df.marks==99).show()\n",
    "df.filter(\"name=='gopi'\").show()\n",
    "df.where((df.marks==99) | (df.name=='sri')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91cda17d-a686-4854-bb82-105b02d2d78d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark-3",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
