{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df764e91-f33d-42cd-8702-3c2d9065b57e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23a1b9f7-e73a-4933-a7b4-0469b0a5622d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8532171107435>:3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m data\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m1\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlokesh\u001B[39m\u001B[38;5;124m'\u001B[39m},{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m2\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgopi\u001B[39m\u001B[38;5;124m'\u001B[39m}]\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#help(spark.createDataFrame)\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mcreateDateFrame(data)\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'SparkSession' object has no attribute 'createDateFrame'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-8532171107435>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m data\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m1\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlokesh\u001B[39m\u001B[38;5;124m'\u001B[39m},{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m2\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgopi\u001B[39m\u001B[38;5;124m'\u001B[39m}]\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#help(spark.createDataFrame)\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mcreateDateFrame(data)\n\n\u001B[0;31mAttributeError\u001B[0m: 'SparkSession' object has no attribute 'createDateFrame'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'SparkSession' object has no attribute 'createDateFrame'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=[{'id':1,'name':'lokesh'},{'id':2,'name':'gopi'}]\n",
    "#help(spark.createDataFrame)\n",
    "df=spark.createDateFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "564cf639-b7ea-4e76-ba24-434d14cae18f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-40173832953157>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#while reading json file which is multiline not in single line we use command multiLine=True\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m help(\u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultiLine\u001B[49m)\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'multiLine'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-40173832953157>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#while reading json file which is multiline not in single line we use command multiLine=True\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m help(\u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultiLine\u001B[49m)\n\n\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'multiLine'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'function' object has no attribute 'multiLine'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#while reading json file which is multiline not in single line we use command multiLine=True\n",
    "help(spark.read.json.multiLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce4cf023-2535-43b4-8f07-80fafc079ab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n| id|  name|\n+---+------+\n|  1|lokesh|\n|  2|  gopi|\n+---+------+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(data)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c7d721-ac87-4f2b-a4c7-ef05892b71cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n| id|name|\n+---+----+\n|  1|GOPI|\n|  2|LOKI|\n+---+----+\n\nroot\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "SCHEMA = StructType([StructField('id',IntegerType()),\n",
    "                StructField('name',StringType())])\n",
    "DATA = [(1,'GOPI'),(2,'LOKI')]\n",
    "DF=spark.createDataFrame(DATA,SCHEMA)\n",
    "DF.show()\n",
    "DF.printSchema()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376b7335-e91b-4d23-b191-0197bef20145",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|    null|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|    null|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|    null|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|    null|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# read instance functions\n",
    "#     read.json\n",
    "#     read.parquet\n",
    "#df1=spark.read.csv('dbfs:/FileStore/shared_uploads/lokeshfrdamma@gmail.com/EmployeeData_8xfZvOlzqL-1.csv')\n",
    "df1=spark.read.format('csv').load('dbfs:/FileStore/shared_uploads/lokeshfrdamma@gmail.com/EmployeeData_8xfZvOlzqL-1.csv',header=True)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b785b1f-9f2a-4b1a-9576-34ba15765d61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- first_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- email: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- creationDate: timestamp (nullable = true)\n |-- bonus: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "schema='id int, first_name string, last_name string, email string, gender string ,salary long , creationDate timeStamp , bonus int'\n",
    "df2=spark.read.format('csv').load('dbfs:/FileStore/shared_uploads/lokeshfrdamma@gmail.com/EmployeeData_8xfZvOlzqL-1.csv',header=True,schema=schema)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b39cfd2-ece2-45dd-b317-00e77e4d02e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>GOPI</td></tr><tr><td>1</td><td>GOPI</td></tr><tr><td>1</td><td>GOPI</td></tr><tr><td>2</td><td>LOKI</td></tr><tr><td>2</td><td>LOKI</td></tr><tr><td>2</td><td>LOKI</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1",
         "GOPI"
        ],
        [
         "1",
         "GOPI"
        ],
        [
         "1",
         "GOPI"
        ],
        [
         "2",
         "LOKI"
        ],
        [
         "2",
         "LOKI"
        ],
        [
         "2",
         "LOKI"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write dataframe into csv file\n",
    "# for different files\n",
    "#             write.json\n",
    "#             write.parquet\n",
    "DF.write.csv('dbfs:/csv/df1',header=True,mode='append')\n",
    "# saving modes\n",
    "#     append\n",
    "#     ignore\n",
    "#     error\n",
    "#     override\n",
    "display(spark.read.csv('dbfs:/csv/df1',header=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acbb6330-5f15-4fd2-ad44-a7636765bd53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n| id|name|\n+---+----+\n|  1|GOPI|\n|  2|LOKI|\n+---+----+\n\nHelp on NoneType object:\n\nclass NoneType(object)\n |  Methods defined here:\n |  \n |  __bool__(self, /)\n |      self != 0\n |  \n |  __repr__(self, /)\n |      Return repr(self).\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  __new__(*args, **kwargs) from builtins.type\n |      Create and return a new object.  See help(type) for accurate signature.\n\n"
     ]
    }
   ],
   "source": [
    "#information about show()\n",
    "help(DF.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "738ec745-8a9b-49de-b2b5-58f2b5a97ca3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------+\n|name  |comments                  |\n+------+--------------------------+\n|lokesh|fjkhfoielujiokljofiadhjl  |\n|gopi  |jhduiwehukyhewuyqwioioqrhe|\n+------+--------------------------+\n\n+------+--------+\n|  name|comments|\n+------+--------+\n|lokesh|fjkhf...|\n|  gopi|jhdui...|\n+------+--------+\n\n+------+--------------------+\n|  name|            comments|\n+------+--------------------+\n|lokesh|fjkhfoielujiokljo...|\n+------+--------------------+\nonly showing top 1 row\n\n-RECORD 0------------------------\n name     | lokesh               \n comments | fjkhfoielujiokljo... \n-RECORD 1------------------------\n name     | gopi                 \n comments | jhduiwehukyhewuyq... \n\n-RECORD 0----------------------------\n name     | lokesh                   \n comments | fjkhfoielujiokljofiadhjl \nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "#changes we can do with show()\n",
    "        #to dipaly full value\n",
    "schema=['name','comments']\n",
    "data=[('lokesh','fjkhfoielujiokljofiadhjl'),('gopi','jhduiwehukyhewuyqwioioqrhe')]\n",
    "df3=spark.createDataFrame(data,schema)\n",
    "df3.show(truncate=False) # to display full value\n",
    "df3.show(truncate=8)# to display up to which character we want\n",
    "df3.show(n=1)# nuber of rows you want to display, by default table shiws 20 rows\n",
    "df3.show(vertical=True)# to diplay content vertically\n",
    "df3.show(n=1,truncate=False,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e475277-df4d-44fc-8e2d-2b3aa9cafa45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark-1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
