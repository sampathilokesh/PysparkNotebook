{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e4eb28c-68e3-45ea-9b39-bc7128f661c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# date functions\n",
    "# default date format is yyyy-MM-dd\n",
    "from pyspark.sql.functions import current_date, date_format,to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29de7822-7384-4f55-a18a-856886031282",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#last_day & date_truc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc9dc08f-0281-4749-aa84-7fda923662ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n| id|currentDate|\n+---+-----------+\n|  1| 2023-12-10|\n|  2| 2023-12-10|\n|  3| 2023-12-10|\n|  4| 2023-12-10|\n|  5| 2023-12-10|\n|  6| 2023-12-10|\n|  7| 2023-12-10|\n|  8| 2023-12-10|\n|  9| 2023-12-10|\n+---+-----------+\n\nroot\n |-- id: long (nullable = false)\n |-- currentDate: date (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.range(1,10)\n",
    "df=df.withColumn('currentDate',current_date())\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7004073a-54e9-454d-aad6-651339fff14c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------------------+\n| id|currentDate|stringDate(dd-MM-yyyy)|\n+---+-----------+----------------------+\n|  1| 2023-12-10|            10-12-2023|\n|  2| 2023-12-10|            10-12-2023|\n|  3| 2023-12-10|            10-12-2023|\n|  4| 2023-12-10|            10-12-2023|\n|  5| 2023-12-10|            10-12-2023|\n|  6| 2023-12-10|            10-12-2023|\n|  7| 2023-12-10|            10-12-2023|\n|  8| 2023-12-10|            10-12-2023|\n|  9| 2023-12-10|            10-12-2023|\n+---+-----------+----------------------+\n\nroot\n |-- id: long (nullable = false)\n |-- currentDate: date (nullable = false)\n |-- stringDate(dd-MM-yyyy): string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "#to specify format of date , it will convert date into string\n",
    "df1=df.withColumn('stringDate(dd-MM-yyyy)',date_format(df.currentDate,'dd-MM-yyyy'))\n",
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eb68953-49b1-40aa-b2a2-abd7540e9cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit,date_add,months_between,add_months,datediff,last_day,date_trunc,round,year,month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d678de-e3e1-4ac7-a773-b6783a5b7755",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------------------+-------------------+\n| id|currentDate|stringDate(dd-MM-yyyy)|date in date format|\n+---+-----------+----------------------+-------------------+\n|  1| 2023-12-10|            10-12-2023|         2023-12-10|\n|  2| 2023-12-10|            10-12-2023|         2023-12-10|\n|  3| 2023-12-10|            10-12-2023|         2023-12-10|\n|  4| 2023-12-10|            10-12-2023|         2023-12-10|\n|  5| 2023-12-10|            10-12-2023|         2023-12-10|\n|  6| 2023-12-10|            10-12-2023|         2023-12-10|\n|  7| 2023-12-10|            10-12-2023|         2023-12-10|\n|  8| 2023-12-10|            10-12-2023|         2023-12-10|\n|  9| 2023-12-10|            10-12-2023|         2023-12-10|\n+---+-----------+----------------------+-------------------+\n\nroot\n |-- id: long (nullable = false)\n |-- currentDate: date (nullable = false)\n |-- stringDate(dd-MM-yyyy): string (nullable = false)\n |-- date in date format: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df2=df1.withColumn('date in date format',to_date(col('stringDate(dd-MM-yyyy)'),'dd-MM-yyyy'))\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0ab0579-9951-4e09-86bf-38861b35ba5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+\n| id|currentDate|   my date|\n+---+-----------+----------+\n|  1| 2023-12-10|2001-07-15|\n|  2| 2023-12-10|2001-07-15|\n|  3| 2023-12-10|2001-07-15|\n|  4| 2023-12-10|2001-07-15|\n|  5| 2023-12-10|2001-07-15|\n|  6| 2023-12-10|2001-07-15|\n|  7| 2023-12-10|2001-07-15|\n|  8| 2023-12-10|2001-07-15|\n|  9| 2023-12-10|2001-07-15|\n+---+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df4=df.withColumn('my date',lit('2001-07-15'))\n",
    "df4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9850f68-8119-4bec-b92b-e1ed8fb956d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+--------+\n| id|currentDate|   my date|datediff|\n+---+-----------+----------+--------+\n|  1| 2023-12-10|2001-07-15|    8183|\n|  2| 2023-12-10|2001-07-15|    8183|\n|  3| 2023-12-10|2001-07-15|    8183|\n|  4| 2023-12-10|2001-07-15|    8183|\n|  5| 2023-12-10|2001-07-15|    8183|\n|  6| 2023-12-10|2001-07-15|    8183|\n|  7| 2023-12-10|2001-07-15|    8183|\n|  8| 2023-12-10|2001-07-15|    8183|\n|  9| 2023-12-10|2001-07-15|    8183|\n+---+-----------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# to find out days between two columns\n",
    "df4.withColumn('datediff',datediff('currentDate','my date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e74efc9-def7-4690-bf60-29e52970bbcf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-------------+\n| id|currentDate|   my date|months beween|\n+---+-----------+----------+-------------+\n|  1| 2023-12-10|2001-07-15|        269.0|\n|  2| 2023-12-10|2001-07-15|        269.0|\n|  3| 2023-12-10|2001-07-15|        269.0|\n|  4| 2023-12-10|2001-07-15|        269.0|\n|  5| 2023-12-10|2001-07-15|        269.0|\n|  6| 2023-12-10|2001-07-15|        269.0|\n|  7| 2023-12-10|2001-07-15|        269.0|\n|  8| 2023-12-10|2001-07-15|        269.0|\n|  9| 2023-12-10|2001-07-15|        269.0|\n+---+-----------+----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# to find out months between two dates\n",
    "df4.withColumn('months beween',round(months_between('currentDate','my date'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba2e507-1c6c-444e-9e41-4555992b71e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+\n| id|currentDate|months add|\n+---+-----------+----------+\n|  1| 2023-12-10|2024-01-10|\n|  2| 2023-12-10|2024-01-10|\n|  3| 2023-12-10|2024-01-10|\n|  4| 2023-12-10|2024-01-10|\n|  5| 2023-12-10|2024-01-10|\n|  6| 2023-12-10|2024-01-10|\n|  7| 2023-12-10|2024-01-10|\n|  8| 2023-12-10|2024-01-10|\n|  9| 2023-12-10|2024-01-10|\n+---+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# to add months to the date \n",
    "df.withColumn('months add',add_months(df4.currentDate,1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c0f5d37-8ff5-42aa-9d97-6d7f263cb878",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+\n| id|currentDate|months add|\n+---+-----------+----------+\n|  1| 2023-12-10|2023-11-10|\n|  2| 2023-12-10|2023-11-10|\n|  3| 2023-12-10|2023-11-10|\n|  4| 2023-12-10|2023-11-10|\n|  5| 2023-12-10|2023-11-10|\n|  6| 2023-12-10|2023-11-10|\n|  7| 2023-12-10|2023-11-10|\n|  8| 2023-12-10|2023-11-10|\n|  9| 2023-12-10|2023-11-10|\n+---+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# to subtract months\n",
    "df.withColumn('months add',add_months(df4.currentDate,-1)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c59f310-2e39-4cb2-b8b8-748b4458a228",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+\n| id|currentDate|   daysadd|\n+---+-----------+----------+\n|  1| 2023-12-10|2023-12-20|\n|  2| 2023-12-10|2023-12-20|\n|  3| 2023-12-10|2023-12-20|\n|  4| 2023-12-10|2023-12-20|\n|  5| 2023-12-10|2023-12-20|\n|  6| 2023-12-10|2023-12-20|\n|  7| 2023-12-10|2023-12-20|\n|  8| 2023-12-10|2023-12-20|\n|  9| 2023-12-10|2023-12-20|\n+---+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# to add days\n",
    "df.withColumn('daysadd',date_add(df4.currentDate,10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e234e8ae-acac-42d6-aeee-6dbb7a5cba79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+\n| id|currentDate|  days sub|\n+---+-----------+----------+\n|  1| 2023-12-10|2023-11-30|\n|  2| 2023-12-10|2023-11-30|\n|  3| 2023-12-10|2023-11-30|\n|  4| 2023-12-10|2023-11-30|\n|  5| 2023-12-10|2023-11-30|\n|  6| 2023-12-10|2023-11-30|\n|  7| 2023-12-10|2023-11-30|\n|  8| 2023-12-10|2023-11-30|\n|  9| 2023-12-10|2023-11-30|\n+---+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# to subtract days\n",
    "df.withColumn('days sub',date_add(df4.currentDate,-10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f64ba2-76f3-4c85-9d2e-8fff87f99f48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------------+\n| id|currentDate|current year|\n+---+-----------+------------+\n|  1| 2023-12-10|        2023|\n|  2| 2023-12-10|        2023|\n|  3| 2023-12-10|        2023|\n|  4| 2023-12-10|        2023|\n|  5| 2023-12-10|        2023|\n|  6| 2023-12-10|        2023|\n|  7| 2023-12-10|        2023|\n|  8| 2023-12-10|        2023|\n|  9| 2023-12-10|        2023|\n+---+-----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#to find out year\n",
    "df.withColumn('current year',year(df4.currentDate)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f64411-bace-4e9f-92c3-03b7450e3a08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-------------+\n| id|currentDate|current month|\n+---+-----------+-------------+\n|  1| 2023-12-10|           12|\n|  2| 2023-12-10|           12|\n|  3| 2023-12-10|           12|\n|  4| 2023-12-10|           12|\n|  5| 2023-12-10|           12|\n|  6| 2023-12-10|           12|\n|  7| 2023-12-10|           12|\n|  8| 2023-12-10|           12|\n|  9| 2023-12-10|           12|\n+---+-----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#to find out month\n",
    "df.withColumn('current month',month(df4.currentDate)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a679cc6-556b-4039-871a-8d3ebdc2b688",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# time stamp\n",
    "from pyspark.sql.functions import current_timestamp,to_timestamp,hour,minute,second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "288819a9-b804-4a78-ab20-6a0847ae93e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+\n|id |currenttime            |\n+---+-----------------------+\n|1  |2023-12-10 09:56:47.984|\n|2  |2023-12-10 09:56:47.984|\n|3  |2023-12-10 09:56:47.984|\n|4  |2023-12-10 09:56:47.984|\n|5  |2023-12-10 09:56:47.984|\n|6  |2023-12-10 09:56:47.984|\n|7  |2023-12-10 09:56:47.984|\n|8  |2023-12-10 09:56:47.984|\n|9  |2023-12-10 09:56:47.984|\n+---+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "dfr=spark.range(1,10)\n",
    "dfr=dfr.withColumn('currenttime ', current_timestamp())\n",
    "dfr.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "964b3c80-4ab0-4551-9954-64c60522a94a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df5=spark.range(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ca73706-08d0-4fc4-83c9-8fd38ff5f9ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df5=df5.withColumn('currentTimeStamp',current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2359559c-4a61-4ecf-b26b-3529f0eb182c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+----+\n|id |currentTimeStamp       |hour|\n+---+-----------------------+----+\n|1  |2023-12-10 10:05:42.426|10  |\n+---+-----------------------+----+\n\n"
     ]
    }
   ],
   "source": [
    "df5.select('*',hour(df5.currentTimeStamp).alias('hour')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603b8087-6262-4b3e-8d29-77fe64911c5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+------+\n|id |currentTimeStamp       |minute|\n+---+-----------------------+------+\n|1  |2023-12-10 10:06:23.601|6     |\n+---+-----------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df5.select('*',minute(df5.currentTimeStamp).alias('minute')).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a6d5c4a-35b4-432b-90f5-9e76724cc947",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark -8 date functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
