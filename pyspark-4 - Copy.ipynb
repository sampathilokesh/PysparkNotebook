{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80bec187-bc1b-43a2-8721-1cbdad7b9f33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33eb8303-c116-473b-80e6-8e4aefdfa614",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  2|gopi| 25|  2000|\n|  3| sri| 22|  2000|\n|  4|hari| 27|  2050|\n|  4|hari| 27|  2050|\n+---+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "classs=Row('id','name','age','salary')\n",
    "stu1=classs(1,'loki','22',2000)\n",
    "stu2=classs(2,'gopi','25',2000)\n",
    "stu3=classs(3,'sri','22',2000)\n",
    "stu4=classs(4,'hari','27',2050)\n",
    "stu4=classs(4,'hari','27',2050)\n",
    "data=[stu1,stu2,stu3,stu4,stu4]\n",
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5a7cfbb-113c-4dab-aa34-18edc0639653",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  2|gopi| 25|  2000|\n|  3| sri| 22|  2000|\n|  4|hari| 27|  2050|\n+---+----+---+------+\n\n+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  2|gopi| 25|  2000|\n|  3| sri| 22|  2000|\n|  4|hari| 27|  2050|\n+---+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# distinct & dropDistinct functions used to get distinct rows $ these removes duplicates from your table\n",
    "# the differemce between didtinct() & dropDuplicates is \n",
    "#       in distinct it filter out based on rows if duplicate rows exists\n",
    "#       in dropDuplicates we can ditinct() in addition we can ge distinct values based on column also by passing list of columns to it \n",
    "df.distinct().show()\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b1f690-9e9e-486c-8083-6fabedd87e2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  4|hari| 27|  2050|\n+---+----+---+------+\n\n+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  2|gopi| 25|  2000|\n|  4|hari| 27|  2050|\n+---+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates(['salary']).show()\n",
    "df.dropDuplicates(['salary','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f07de28-2ed2-45ad-b645-245ed4a0cc74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  2|gopi| 25|  2000|\n|  4|hari| 27|  2050|\n|  4|hari| 27|  2050|\n|  1|loki| 22|  2000|\n|  3| sri| 22|  2000|\n+---+----+---+------+\n\n+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  4|hari| 27|  2050|\n|  4|hari| 27|  2050|\n|  3| sri| 22|  2000|\n|  2|gopi| 25|  2000|\n|  1|loki| 22|  2000|\n+---+----+---+------+\n\n+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  4|hari| 27|  2050|\n|  4|hari| 27|  2050|\n|  2|gopi| 25|  2000|\n|  3| sri| 22|  2000|\n|  1|loki| 22|  2000|\n+---+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "# sort & orderBy functions\n",
    "df.sort('name').show()\n",
    "df.sort(df.id.desc()).show()\n",
    "df.orderBy(df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a8754c3-d40c-4a56-b44b-0df7cf463caf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# union & unionAll() -> these operations will ue when you have similar schema\n",
    "#in sql  union -> used to merge tow tables with removing duplicates and union all merge two tables regardless of duplicates it will merge with duplicate rows,\n",
    "# in pyspark union and unionAll merge tow dataferames then create new dataframe without removing duplicates , we can remove duplicates using distinct() operation\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3479e43a-7877-407d-b3b1-6b06e90439db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  6|loki| 22|  2000|\n|  7|gopi| 25|  2000|\n|  8| sri| 22|  2000|\n|  9|hari| 27|  2050|\n+---+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "class2=Row('id','name','age','salary')\n",
    "stu1=class2(6,'loki','22',2000)\n",
    "stu2=class2(7,'gopi','25',2000)\n",
    "stu3=classs(8,'sri','22',2000)\n",
    "stu4=class2(9,'hari','27',2050)\n",
    "data=[stu1,stu2,stu3,stu4]\n",
    "df1=spark.createDataFrame(data)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1762810-b08a-4cab-ab9f-1a341cbe8b26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  2|gopi| 25|  2000|\n|  3| sri| 22|  2000|\n|  4|hari| 27|  2050|\n|  4|hari| 27|  2050|\n|  6|loki| 22|  2000|\n|  7|gopi| 25|  2000|\n|  8| sri| 22|  2000|\n|  9|hari| 27|  2050|\n+---+----+---+------+\n\n+---+----+---+------+\n| id|name|age|salary|\n+---+----+---+------+\n|  1|loki| 22|  2000|\n|  2|gopi| 25|  2000|\n|  3| sri| 22|  2000|\n|  4|hari| 27|  2050|\n|  4|hari| 27|  2050|\n|  6|loki| 22|  2000|\n|  7|gopi| 25|  2000|\n|  8| sri| 22|  2000|\n|  9|hari| 27|  2050|\n+---+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "df2=df.union(df1)\n",
    "df2.show()\n",
    "df3=df.unionAll(df1)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a429dbe9-1ff9-4fae-8cfb-eafeaad07762",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n|  name|age|\n+------+---+\n|lokesh| 22|\n+------+---+\n\n+-----+------+\n| name|salary|\n+-----+------+\n|gopal| 20000|\n+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "data1=[('lokesh',22)]\n",
    "schema1=['name','age']\n",
    "dfr1=spark.createDataFrame(data1,schema1)\n",
    "\n",
    "data2=[('gopal',20000)]\n",
    "schema2=['name','salary']\n",
    "dfr2=spark.createDataFrame(data2,schema2)\n",
    "dfr1.show()\n",
    "dfr2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcae3a18-9aea-45d1-a807-72cb9522e83f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n|  name| age|salary|\n+------+----+------+\n|lokesh|  22|  null|\n| gopal|null| 20000|\n+------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# unionByName -> use dto merge two dataframes eventhough dataframe schema is different, but we need pass on parameter here that is allowMissingColumns=True\n",
    "dfr1.unionByName(dfr2,allowMissingColumns=True).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b48ab3-bebe-4aa8-9e24-00a5f829c9ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n|age|count|\n+---+-----+\n| 22|    4|\n| 25|    2|\n| 27|    3|\n+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# gropuBy class is used to group the data based on columns and return grouped data, wwe can also perform aggregation like max , count,min,avg, mean opaarations on ths data\n",
    "df4=df2.groupBy('age').count()\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea391726-d9ee-4b46-9f36-e3b3ac33c7d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n|age|max(salary)|\n+---+-----------+\n| 22|       2000|\n| 25|       2000|\n| 27|       2050|\n+---+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(df2.age).max('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73fe0ac5-1bac-421b-83e9-8fc1b82f5861",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# performing multiple aggregate function on single data frame\n",
    "from pyspark.sql.functions import count, max, min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03a4263f-e57b-4aaf-9f0a-a42505261af1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------+----------------------------+\n|age|count of students |maxium salry|mimimum salary for this age |\n+---+------------------+------------+----------------------------+\n| 22|                 2|        2000|                        2000|\n| 25|                 1|        2000|                        2000|\n| 27|                 2|        2050|                        2050|\n+---+------------------+------------+----------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('age').agg(count('*').alias('count of students '),\\\n",
    "    max('salary').alias('maxium salry'),\\\n",
    "    min('salary').alias('mimimum salary for this age ')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac27ec58-41f8-40c1-83b9-69390b8872ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark-4",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
